# How can we re-define learning / education in the age of AI?

## Introduction

In a world increasingly shaped by artificial intelligence and digital tools, the boundaries of human learning are rapidly evolving. With knowledge now just a click—or a prompt—away, the role of memory, practice, and internal understanding is under threat. Educators and learners alike face a fundamental question: what does it mean to “know” something when machines can provide instant answers? The goal of this synthesis is to reexamine the relationship between human cognition and technological assistance, and to propose a clearer definition of how digital tools should serve—not replace—the core processes of learning.

Across the studies reviewed in this collection, a consistent insight emerges: internal knowledge is not optional—it is essential. Neuroscience shows that memory is not just storage, but a foundation for reasoning, creativity, and critical thinking. Yet modern education, in its enthusiasm for “21st-century skills,” has too often abandoned core content and memorization, creating a dangerous dependency on external aids. This shift not only undermines deep learning but confuses students and teachers about the purpose of education in an AI-saturated environment. We must now ask: where should we draw the line between helpful offloading and harmful overreliance?

This collection seeks to clarify that line. By integrating insights from cognitive science, educational theory, and technology research, we explore a new vision for education—one that embraces intelligent tools but anchors them in a strong understanding of how learning actually works. We examine what the future of instruction might look like when grounded in the realities of brain-based learning, and propose new forms of assessment that measure not just output, but the internal skills and fluencies that underlie genuine expertise. This is not just about adapting to change—it is about defining it on our terms.

### Paper: “The Memory Paradox: Why Our Brains Need Knowledge in an Age of AI.”

Oakley, B., Johnston, M., Chen, K.-Z., Jung, E., & Sejnowski, T. (2025).In The Future of Artificial Intelligence: Economics, Society, Risks and Global Policy (Springer Nature).[Available here](https://papers.ssrn.com/sol3/papers.cfm?abstract_id=5250447)
Even in an age of AI and Google, your brain still needs to remember stuff.

#### Summary: 

Offloading knowledge to machines makes life easier in the short term—but it weakens the brain’s ability to think deeply, solve problems, and learn new things. To stay smart, we must practice and store knowledge in our own memory—not just in our devices.

This paper explains a paradox: while technology makes it easy to “look things up,” our brains actually require internal memory to think effectively. Drawing from neuroscience and psychology, the authors show how skills and knowledge must be practiced and remembered—not just accessed—to form the mental structures (called schemata) that support deep understanding. Over-reliance on AI and digital tools can block this process, weakening both memory and cognition. The authors call for a balanced approach: use technology to enhance thinking, but never let it replace foundational human learning.

#### Problem and Suggestions: 

In today’s hyper-connected world, many people rely on digital tools—like search engines, calculators, and AI assistants—to manage information. This habit, known as cognitive offloading, **offers convenience and speed, but it comes with hidden costs**. As we increasingly outsource memory and problem-solving to technology, we may be weakening the very mental systems that make us capable of deep learning and critical thinking. Modern education often reflects this trend, encouraging students to “look it up” rather than internalize knowledge. Yet this research suggests that this shift may be contributing to declining cognitive performance and a worrying erosion of core learning capacities. **Students may pass exams by relying on external aids, but lack real understanding or mental flexibility—skills that matter far more in the long run than short-term performance.**

Neuroscience helps explain why. The human brain depends on two interconnected memory systems: the declarative system, which helps us consciously recall facts, and the procedural system, which turns practiced knowledge into automatic skills. Deep, transferable learning happens when knowledge is moved from declarative to procedural memory through repetition and retrieval. *This process forms mental frameworks known as schemata, which allow us to make sense of complex problems, detect patterns, and build new knowledge*. But these frameworks can’t form without engagement and practice. **Overreliance on digital tools short-circuits this process—when students constantly look things up instead of remembering them, they don’t give their brains the opportunity to internalize patterns or build mental agility.**

To address this challenge, the authors of “The Memory Paradox” suggest a new path forward. They call on educators to **re-embrace memorization and retrieval practice—not as mindless drills, but as essential processes that strengthen the brain’s learning systems**. They advocate **using AI and digital tools as support, not substitutes, ensuring these tools enhance rather than replace cognitive effort**. Crucially, they recommend that **we teach students how memory works, and why it matters, so learners understand the value of what they hold in their own minds—not just what they can access externally**. <u>*This balanced approach is not about rejecting technology, but about defining its rightful place in the learning process*</u>. When students build strong internal knowledge and use tools to extend—not replace—their thinking, they become far better equipped for lifelong learning and real-world problem-solving.


